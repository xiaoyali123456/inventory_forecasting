{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e255b0e5",
   "metadata": {},
   "source": [
    "# Run Cohort Distribution Analysis for IPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b768911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "out_path = 's3://adtech-ml-perf-ads-us-east-1-prod-v1/live_inventory_forecasting/data/sampling/watched_time_for_collapse/'\n",
    "watched_video_path = 's3://hotstar-ads-ml-us-east-1-prod/data_exploration/data/data_backup/watched_video/'\n",
    "\n",
    "@F.udf(returnType=StringType())\n",
    "def parse(segments):\n",
    "    try:\n",
    "        js = json.loads(segments)\n",
    "        if type(js) == list:\n",
    "            lst = js\n",
    "        else:\n",
    "            lst =js.get('data', [])\n",
    "    except:\n",
    "        return None\n",
    "    filtered = set()\n",
    "    equals = ['A_15031263', 'A_94523754', 'A_40990869', 'A_21231588', # device price\n",
    "              'A_34365936', 'A_49094287', 'AP_107', 'AP_2AS', 'AP_2AT'] # sponsor custom cohort\n",
    "    prefixs = ['NCCS_', 'FMD00', 'MMD00']\n",
    "    middles = ['_MALE_', '_FEMALE_']\n",
    "    for t in lst:\n",
    "        match = False\n",
    "        for s in equals:\n",
    "            if t == s:\n",
    "                match = True\n",
    "                break\n",
    "        if not match:\n",
    "            for s in prefixs:\n",
    "                if t.startswith(s):\n",
    "                    match = True\n",
    "                    break\n",
    "        if not match:\n",
    "            for s in middles:\n",
    "                if s in t:\n",
    "                    match = True\n",
    "                    break\n",
    "        if match:\n",
    "            filtered.add(t)\n",
    "    return '|'.join(sorted(filtered))\n",
    "\n",
    "def process(dt, tour):\n",
    "    print('process', dt)\n",
    "    print('begin', pd.datetime.now())\n",
    "    npar = 32\n",
    "    # out_table_path = f'{out_path}quarter_data/tournament=wc2022/cd={dt}/'\n",
    "    out_table_path = f'{out_path}quarter_data/tournament={tour}/cd={dt}/'\n",
    "    success_path = f'{out_table_path}_SUCCESS'\n",
    "    if os.system('aws s3 ls ' + success_path) == 0:\n",
    "        return\n",
    "    wt_path = f'{watched_video_path}cd={dt}/'\n",
    "    wt = spark.read.parquet(wt_path)\n",
    "    # debug = True\n",
    "    debug = False\n",
    "    if debug:\n",
    "        wt = spark.read.parquet('s3://hotstar-ads-ml-us-east-1-prod/data_exploration/data/data_backup/watched_video/cd=2022-10-16/part-00163-7313c8ab-82bf-482e-be26-aeedfe9e9478-c000.snappy.parquet')\n",
    "        out_table_path = f'{out_path}debug_out_table/'\n",
    "        npar = 1\n",
    "    wt1 = wt[['dw_d_id',\n",
    "        F.expr('lower(genre) == \"cricket\" as is_cricket'),\n",
    "        F.expr('lower(language) as language'),\n",
    "        F.expr('lower(platform) as platform'),\n",
    "        F.expr('lower(country) as country'),\n",
    "        F.expr('lower(city) as city'),\n",
    "        F.expr('lower(state) as state'),\n",
    "        F.expr('case when watch_time < 86400 then watch_time else 0 end as watch_time'),\n",
    "        parse('user_segments').alias('segments'),\n",
    "    ]]\n",
    "    wt2 = wt1.groupby('is_cricket', 'language', 'platform', 'country', 'city', 'state', 'segments').agg(\n",
    "            F.expr('sum(watch_time) as watch_time'),\n",
    "            F.expr('count(distinct dw_d_id) as reach')\n",
    "        ).repartition(npar)\n",
    "    wt2.write.mode('overwrite').parquet(out_table_path)\n",
    "    print('end', pd.datetime.now())\n",
    "    if debug:\n",
    "        res = spark.read.parquet(out_table_path)\n",
    "        res.show()\n",
    "        print(res.count())\n",
    "\n",
    "@F.udf(returnType=StringType())\n",
    "def nccs(segments):\n",
    "    if segments is not None:\n",
    "        for x in segments.split('|'):\n",
    "            if x.startswith('NCCS_'):\n",
    "                return x\n",
    "    return 'other'\n",
    "\n",
    "@F.udf(returnType=StringType())\n",
    "def gender(segments):\n",
    "    if segments is not None:\n",
    "        for x in segments.split('|'):\n",
    "            if x.startswith('FMD00') or '_FEMALE_' in x:\n",
    "                return 'f'\n",
    "            if x.startswith('MMD00') or '_MALE_' in x:\n",
    "                return 'm'\n",
    "    return 'other'\n",
    "\n",
    "@F.udf(returnType=StringType())\n",
    "def age(segments):\n",
    "    dc = {\n",
    "        'FB_MALE_35-44',\n",
    "        'FB_MALE_45-54',\n",
    "        'FB_MALE_55-64',\n",
    "        'FB_MALE_65PLUS',\n",
    "        'FB_FEMALE_35-44',\n",
    "        'FB_FEMALE_45-54',\n",
    "        'FB_FEMALE_55-64',\n",
    "        'FB_FEMALE_65PLUS',\n",
    "        'FB_BARC_FEMALE_31-40',\n",
    "        'FB_BARC_FEMALE_41-50',\n",
    "        'FB_BARC_FEMALE_51+',\n",
    "        'FB_BARC_MALE_31-40',\n",
    "        'FB_BARC_MALE_41-50',\n",
    "        'FB_BARC_MALE_51+',\n",
    "        'EMAIL_MALE_35-44',\n",
    "        'EMAIL_MALE_45-54',\n",
    "        'EMAIL_MALE_55-64',\n",
    "        'EMAIL_MALE_65PLUS',\n",
    "        'EMAIL_FEMALE_35-44',\n",
    "        'EMAIL_FEMALE_45-54',\n",
    "        'EMAIL_FEMALE_55-64',\n",
    "        'EMAIL_FEMALE_65PLUS',\n",
    "        'EMAIl_BARC_FEMALE_31-40',\n",
    "        'EMAIl_BARC_FEMALE_41-50',\n",
    "        'EMAIl_BARC_FEMALE_51+',\n",
    "        'EMAIl_BARC_MALE_31-40',\n",
    "        'EMAIl_BARC_MALE_41-50',\n",
    "        'EMAIl_BARC_MALE_51+',\n",
    "        'PHONE_MALE_35-44',\n",
    "        'PHONE_MALE_45-54',\n",
    "        'PHONE_MALE_55-64',\n",
    "        'PHONE_MALE_65+',\n",
    "        'PHONE_FEMALE_35-44',\n",
    "        'PHONE_FEMALE_45-54',\n",
    "        'PHONE_FEMALE_55-64',\n",
    "        'PHONE_FEMALE_65+',\n",
    "        'PHONE_MALE_TV_31-40',\n",
    "        'PHONE_MALE_TV_41-50',\n",
    "        'PHONE_MALE_TV_51-60',\n",
    "        'PHONE_MALE_TV_60+',\n",
    "        'PHONE_FEMALE_TV_31-40',\n",
    "        'PHONE_FEMALE_TV_41-50',\n",
    "        'PHONE_FEMALE_TV_51-60',\n",
    "        'PHONE_FEMALE_TV_60+',\n",
    "        'PHONE_BARC_FEMALE_31-40',\n",
    "        'PHONE_BARC_FEMALE_41-50',\n",
    "        'PHONE_BARC_FEMALE_51+',\n",
    "        'PHONE_BARC_MALE_31-40',\n",
    "        'PHONE_BARC_MALE_41-50',\n",
    "        'PHONE_BARC_MALE_51+',\n",
    "        'FMD009V0053599SRMLDESTADS',\n",
    "        'MMD009V0053599SRMLDESTADS',\n",
    "        'FMD009V0053599HIGHSRMLDESTADS',\n",
    "        'MMD009V0053599HIGHSRMLDESTADS',\n",
    "    }\n",
    "    if segments is not None:\n",
    "        for x in segments.split('|'):\n",
    "            if x in dc:\n",
    "                return '30+'\n",
    "    return 'other'\n",
    "\n",
    "@F.udf(returnType=StringType())\n",
    "def device(segments):\n",
    "    if segments is not None:\n",
    "        dc = {'A_40990869': '25K+', 'A_21231588': '25K+'}\n",
    "        for x in segments.split('|'):\n",
    "            if x in dc:\n",
    "                return dc[x]\n",
    "    return 'other'\n",
    "\n",
    "def batch_process():\n",
    "    for dt in pd.date_range('2022-03-26', '2022-04-09'):\n",
    "        process(dt.date(), 'ipl2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbf437",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba52df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def postprocess():\n",
    "    df = spark.read.parquet(f'{out_path}quarter_data/')\n",
    "    pdf = df.groupby(\n",
    "        'cd', 'is_cricket', 'tournament',\n",
    "        'country', 'language', 'platform', 'city', 'state',\n",
    "        nccs('segments').alias('nccs'), \n",
    "        device('segments').alias('device'),\n",
    "        gender('segments').alias('gender'),\n",
    "        age('segments').alias('age'),\n",
    "    ).agg(F.sum('watch_time').alias('watch_time'),\n",
    "          F.sum('reach').alias('reach'))\n",
    "    pdf.repartition(8).write.mode('overwrite').parquet(f'{out_path}quarter_data_v2_1') # add IPL 2022\n",
    "\n",
    "postprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b62044",
   "metadata": {},
   "source": [
    "# Reach Approximation Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d06721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot 17003329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx 29524843\n"
     ]
    }
   ],
   "source": [
    "def total_reach(dt):\n",
    "    wt_path = f'{watched_video_path}cd={dt}/'\n",
    "    wt = spark.read.parquet(wt_path)\n",
    "    return wt.select('dw_d_id').distinct().count()\n",
    "\n",
    "def approx_reach(dt):\n",
    "    path = f'{out_path}quarter_data/tournament=wc2022/cd={dt}/'\n",
    "    df = spark.read.parquet(path)\n",
    "    return df[['reach']].toPandas().reach.sum()\n",
    "\n",
    "dt = '2022-10-23'\n",
    "print('tot', total_reach(dt))\n",
    "print('approx', approx_reach(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6b62ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.73641543958833"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29524843/17003329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb896b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
