{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6108a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'spark0' not in globals():\n",
    "    spark0 = spark\n",
    "    spark = SparkSession.builder \\\n",
    "        .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\") \\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://metastore.data.hotstar-labs.com:9083\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ec9e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "out_path = 's3://adtech-ml-perf-ads-us-east-1-prod-v1/live_inventory_forecasting/data/subs_AU/'\n",
    "order_path = 's3://hotstar-ads-ml-us-east-1-prod/content-insight/content_return/subs_retention/data/order_base/'\n",
    "AU_table = 'data_warehouse.viewed_page_daily_aggregates_ist'\n",
    "\n",
    "def s3_exist(path):\n",
    "    return 0 == os.system(f'aws s3 ls {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc997784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "order = spark.read.parquet(order_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_cache_enabled = False\n",
    "cache_month = ''\n",
    "\n",
    "for i in pd.date_range('2022-01-01', '2023-01-01'):\n",
    "    cd = str(i.date())\n",
    "    real_path = f'{out_path}cd={cd}/'\n",
    "    print(datetime.now(), real_path)\n",
    "    if s3_exist(real_path + '_SUCCESS'):\n",
    "        continue\n",
    "    if month_cache_enabled:\n",
    "        month = cd[:7]\n",
    "        if cache_month != month:\n",
    "            print(11)\n",
    "            if 'order2' in globals():\n",
    "                print(22)\n",
    "                order2.unpersist()\n",
    "            print(33)\n",
    "            order2 = order.where(f'substr(order_start_date, 1, 7) <= \"{cache_month}\" and substr(actual_order_end_date, 1, 7) >= \"{cache_month}\"')\n",
    "            print(order2.count())\n",
    "            cache_month = month\n",
    "    else:\n",
    "        order2 = order\n",
    "    vp = spark.sql(f'select dw_p_id from {AU_table} where cd = \"{cd}\"')\n",
    "    order3 = order2.where(f'order_start_date <= \"{cd}\" and actual_order_end_date >= \"{cd}\" and is_cancel = 0')\n",
    "    vp.join(order3, 'dw_p_id').groupby('partner', 'billing_interval_unit', 'billing_frequency').agg(F.countDistinct('dw_p_id').alias('n_pid')) \\\n",
    "        .repartition(1).write.mode('overwrite').parquet(real_path)\n",
    "    print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805ccef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e372b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
